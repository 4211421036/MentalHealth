<!doctype html><html lang=en lang=en xml:lang=en><head><meta charset=UTF-8><meta content="width=device-width,initial-scale=1" name=viewport><title>About Us - Mental Health Website</title><link href=https://4211421036.github.io/MentalHealth/ rel=canonical><link href=https://4211421036.github.io/g4lihru/987654567.png rel=preload type=image/x-icon as=image><link href=https://4211421036.github.io/g4lihru/987654567.png rel="shortcut icon" type=image/x-icon><link href=https://4211421036.github.io/g4lihru/987654567.png rel=icon type=image/x-icon><link href=https://4211421036.github.io/MentalHealth/style.css rel=preload as=style><link href=https://4211421036.github.io/g4lihru/987654567.png rel=apple-touch-icon><link href=https://4211421036.github.io/ rel=dns-prefetch><meta content="A comprehensive mental health monitoring application using modern web technologies" name=description><meta content="mental health, monitoring, health app, face analysis, emotion detection" name=keywords><meta content="GALIH RIDHO UTOMO and Ana Maulida" name=author><meta content="index, follow" name=robots><meta content=en http-equiv=Content-Language><meta content="max-age=180, public, must-revalidate" http-equiv=Cache-Control><meta content=nosniff http-equiv=X-Content-Type-Options><meta content="no-cache, no-store, must-revalidate" http-equiv=Cache-Control><meta content=no-cache http-equiv=Pragma><meta content=0 http-equiv=Expires><meta content="dark light" name=color-scheme><meta content="Mental Health" property=og:title><meta content="A comprehensive mental health monitoring application using modern web technologies" property=og:description><meta content=https://4211421036.github.io/g4lihru/987654567.png property=og:image><meta content=https://4211421036.github.io/MentalHealth property=og:url><meta content=425 property=og:image:width><meta content=425 property=og:image:height><meta content=website property=og:type><meta content="Light Dark" http-equiv=default-style><meta content=en_US property=og:locale><meta content=id_ID property=og:locale:alternate><meta content="Mental Health" property=og:site_name><meta content=@ITBGRU name=twitter:site><meta content=@ITBGRU name=twitter:creator><meta content=4211421036.github.io name=twitter:domain><meta content=https://4211421036.github.io/MentalHealth name=twitter:url><meta content=https://4211421036.github.io/g4lihru/987654567.png name=twitter:image:src><meta content="Mental Health" name=twitter:image:alt><meta content=summary_large_image name=twitter:card><meta content="Mental Health" name=twitter:title><meta content="A comprehensive mental health monitoring application using modern web technologies" name=twitter:description><meta content=https://4211421036.github.io/g4lihru/987654567.png name=twitter:image><style>:root{--primary-color:#12528a;--background-light:#f7f9fb;--background-white:#ffffff;--text-color:#333333;--border-color:#e0e0e0;--secondary-color:#3d729c;--header-color:#0d47a1}*{box-sizing:border-box;margin:0;padding:0}body{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Helvetica,Arial,sans-serif;line-height:1.6;background-color:var(--background-light);color:var(--text-color)}.page-wrapper{display:flex;flex-direction:column;min-height:100vh}.top-navigation{background-color:var(--background-white);padding:10px 40px;border-bottom:1px solid var(--border-color);display:flex;align-items:center;position:relative;z-index:1;top:70px}.breadcrumbs{display:flex;gap:10px;align-items:center}.breadcrumbs a{text-decoration:none;color:var(--text-color)}.breadcrumbs a.active{color:var(--primary-color);font-weight:500}.main-content{display:flex;max-width:1200px;margin:0 auto;padding:40px 20px}.content-area{flex:1;max-width:800px;top:40px;position:relative}.page-header{margin-bottom:20px}.page-meta{color:#666;font-size:14px;margin-bottom:20px}h1{font-size:2.5rem;margin-bottom:25px;font-weight:700}h2{font-size:1.75rem;margin:40px 0 20px;font-weight:600}h3{font-size:1.4rem;margin:30px 0 15px;font-weight:600}p{margin-bottom:20px;font-size:16px}.content-section{margin-bottom:40px}.team-table{width:100%;border-collapse:collapse;margin:20px 0 30px;background-color:var(--background-white);box-shadow:0 1px 3px rgba(0,0,0,.1);border-radius:4px;overflow:hidden}.team-table td,.team-table th{padding:12px 15px;text-align:left;border-bottom:1px solid var(--border-color)}.team-table th{background-color:#f5f7f9;font-weight:600}.team-table tr:last-child td{border-bottom:none}.team-table a{color:var(--primary-color);text-decoration:none}.team-table a:hover{text-decoration:underline}.code-block{background:#f5f7f9;padding:15px;border-radius:4px;border-left:3px solid var(--primary-color);margin:20px 0;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,monospace;font-size:14px;line-height:1.5;overflow-x:auto}.edit-page{display:flex;align-items:center;padding:10px 15px;background-color:var(--background-white);border:1px solid var(--border-color);border-radius:6px;text-decoration:none;color:var(--text-color);margin-bottom:30px;width:fit-content}.edit-page svg{margin-right:8px}.footer{margin-top:auto;background-color:var(--background-white);padding:20px 40px;border-top:1px solid var(--border-color);text-align:center;font-size:14px;color:#666}.icon{display:inline-flex;width:18px;height:18px;margin-right:8px;color:#64748b}.sidebar{position:sticky;top:20px;max-height:100vh;overflow-y:auto;padding:20px;background-color:#f9f9f9;border-radius:8px;margin-left:20px}.sidebar-title{font-size:18px;font-weight:600;color:#333;margin-bottom:16px;padding-left:12px}.sidebar-nav{list-style:none;padding-left:0;margin:0}.sidebar-nav li a{display:block;padding:10px 12px;color:#555;text-decoration:none;transition:all .3s ease;border-radius:4px;margin:4px 0}.sidebar-nav li a:hover{background-color:#e3f2fd;color:#1976d2}.sidebar-nav li a.active{background-color:#1976d2;color:#fff;font-weight:500}.sidebar-nav li.level-2{padding-left:20px}.sidebar-nav li.level-3{padding-left:40px}.sidebar-nav li.level-2::before,.sidebar-nav li.level-3::before{content:'';position:absolute;left:12px;width:2px;height:100%;background-color:#e0e0e0}.sidebar-nav li.level-2::before{top:0;height:100%}.sidebar-nav li.level-3::before{top:0;height:100%}.card-container{display:flex;justify-content:flex-start;align-items:flex-start;padding:20px}.card{width:400px;background:#fff;border-radius:12px;box-shadow:0 4px 6px rgba(0,0,0,.1);overflow:hidden;transition:transform .3s ease,box-shadow .3s ease;position:relative}.card:hover{transform:translateY(-10px);box-shadow:0 12px 24px rgba(0,0,0,.2)}.card-icon{display:flex;justify-content:center;align-items:center;padding:20px;background-color:#f9f9f9}.card-icon svg{width:50px;height:50px;fill:#333}.card-content{padding:20px;text-align:center}.card-title{font-size:20px;font-weight:600;color:#333;margin-bottom:10px}.card-description{font-size:14px;color:#666;margin-bottom:20px}.card-link{display:inline-block;padding:10px 20px;background-color:#1976d2;color:#fff;text-decoration:none;border-radius:6px;position:relative;transition:background-color .3s ease}.card-link:hover{background-color:#1565c0}.card::before{content:'';position:absolute;top:0;left:0;width:100%;height:100%;background:rgba(25,118,210,.1);opacity:0;transition:opacity .3s ease}.card:hover::before{opacity:1}header{position:fixed;top:0;left:0;right:0;height:70px;background:var(--nav-bg);display:flex;justify-content:space-between;align-items:center;backdrop-filter:blur(20px);-webkit-backdrop-filter:blur(20px);border-bottom:1px solid var(--border);padding:0 20px;z-index:2}.headco{display:flex;justify-content:space-between;align-items:start;flex-direction:column}.logos{margin:0}</style><script nonce="WFV9sDq7d03R5LMneBB3ow==" async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script nonce="WFV9sDq7d03R5LMneBB3ow==">document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll("h2, h3"),t=document.querySelectorAll(".sidebar-nav a");window.addEventListener("scroll",()=>{let n="";e.forEach(e=>{var t=e.getBoundingClientRect().top;t<=window.innerHeight/2&&t>=-e.offsetHeight&&(n=e.getAttribute("id"))}),t.forEach(e=>{e.classList.remove("active"),e.getAttribute("href").includes(n)&&e.classList.add("active")})})})</script></head><body><header aria-label="Main Header"><div class=headco><h1 class=logos>Mental Health</h1></div></header><div class=page-wrapper><nav class=top-navigation><div class=breadcrumbs><a href=https://4211421036.github.io/MentalHealth/ >HOME</a> <span>/</span> <a href=/about class=active>ABOUT</a></div></nav><div class=main-content><div class=content-area><div class=page-meta>Page last updated: February 5, 2025</div><div class=page-header><h1>About Mental Health Website</h1></div><div class=content-section><p>Mental Health Website is a public, open-source resource for the mental health community that anyone can contribute to. We have a small core team dedicated to maintaining and developing the site with contributions from thousands of community members across the globe.</p><p><strong>Nobody from Mental Health Website will ever contact you. Do not respond.</strong></p></div><div class=content-section><h2 id=a-note-on-mental-health>A Note on Mental Health</h2><p>It is common for individuals to confuse terms within the mental health landscape, which can lead to poor mental models about how mental health works. Here is a brief explanation to clarify these concepts:</p><h3 id=mental-health-basics>Mental Health Basics</h3><p>Mental health is a public concern, a personal journey, and an open-source collaborative effort -- operated, governed, managed, and owned by a global community of tens of thousands of professionals, researchers, supporters, and users.</p><div class=card-container><div class=card><div class=card-icon><svg fill=currentColor viewBox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.652.242 2.873.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg></div><div class=card-content><h3 class=card-title>GitHub Repository Mental Health</h3><p class=card-description>A comprehensive mental health monitoring application using modern web technologies.</p><a href=https://github.com/4211421036/MentalHealth/ class=card-link>Visit GitHub Mental Health</a></div></div></div></div><div class=content-section><h2 id=our-team>Our Team</h2><table class=team-table><thead><tr><th>Name</th><th>Role</th><th>Social Media</th><th>Contact</th></tr></thead><tbody><tr><td>GALIH RIDHO UTOMO</td><td>Developer</td><td><a href=https://www.instagram.com/galih_ridho_utomo/ >Instagram</a></td><td>g4lihru@students.unnes.ac.id</td></tr><tr><td>Ana Maulida</td><td>Writing Ilmiah</td><td><a href=https://www.instagram.com/anma1505/ >Instagram</a></td><td>anamaulida@students.unnes.ac.id</td></tr></tbody></table></div><div class=content-section><h2 id=features>Features</h2><p>Our website provides various tools and resources to help you monitor and improve your mental health:</p><ul><li>Real-time emotion detection using facial analysis</li><li>Mental health tracking with sensor data integration</li><li>Personalized advice based on your emotional state</li><li>Community support and resources for mental health awareness</li></ul></div><div class=content-section><h2 id=code-examples>Code Examples</h2><p>Here is the complete code snippet from our <code>face-analysis.js</code> that you can use to integrate emotion detection into your own projects. Each function is explained in detail below, along with mathematical formulas to represent the logic:</p><h3>1. Hash Function (djb2Hash)</h3><p>This function generates a unique hash value for a given string. It is based on the DJB2 algorithm, which is a simple and efficient hashing algorithm.</p><div class=code-block><pre><code>// djb2Hash: Generates a hash value for a string
function djb2Hash(str) {
    let hash = 5381; // Initial hash value
    for (let i = 0; i<str.length hash=(hash hash * 33)^str.charcodeat(i); ; i++) return { }>>> 0;
}</str.length></code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ h_0 = 5381 \\ h_i = ((h_{i-1} \times 33) \oplus c_i) \mod 2^{32}, \quad \text{for } i = 1,2,\ldots,n \]</p><p><strong>Explanation:</strong></p><ul><li>\(h_0 = 5381\): Initial hash value</li><li>\(h_i\): Hash value after processing the \(i\)-th character</li><li>\(c_i\): ASCII/Unicode value of the \(i\)-th character (obtained using <code>charCodeAt(i)</code>)</li><li>\(\oplus\): Bitwise XOR operation</li><li>\(\mod 2^{32}\): Conversion to unsigned 32-bit integer (equivalent to <code>>>> 0</code> in JavaScript)</li></ul><h3>2. Generate Face ID (generateFaceID)</h3><p>This function converts facial landmarks into a unique hash string. It normalizes the landmark coordinates and uses the <code>djb2Hash</code> function to generate a unique FaceID.</p><div class=code-block><pre><code>// generateFaceID: Converts facial landmarks to a unique hash
function generateFaceID(landmarks) {
    // Normalize landmark coordinates with 4 decimal precision
    let hashString = landmarks.map(lm =>
        lm.x.toFixed(4) +
        lm.y.toFixed(4) +
        lm.z.toFixed(4)
    ).join('');

    return djb2Hash(hashString).toString(16); // Convert to hexadecimal
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ S = \text{concatenate}_{j=1}^{n} \left( \text{round}(L_j.x, 4) \cdot \text{round}(L_j.y, 4) \cdot \text{round}(L_j.z, 4) \right) \\ \text{FaceID} = \text{hex}(\text{djb2Hash}(S)) \]</p><p><strong>Explanation:</strong></p><ul><li>\(L_j\): The \(j\)-th facial landmark containing \(x\), \(y\), and \(z\) coordinates</li><li>\(\text{round}(v, 4)\): Rounding the value \(v\) to 4 decimal places (equivalent to <code>toFixed(4)</code>)</li><li>\(S\): Concatenated string of all normalized landmark coordinates</li><li>\(\text{djb2Hash}(S)\): Application of the hash function to the string \(S\)</li><li>\(\text{hex}(v)\): Conversion of value \(v\) to hexadecimal representation (equivalent to <code>toString(16)</code>)</li></ul><h3>3. Analyze Emotions (analyzeEmotions)</h3><p>This function calculates the intensity of different emotions (happy, sad, angry, surprised, neutral) based on facial landmarks.</p><div class=code-block><pre><code>// analyzeEmotions: Calculates emotion intensities
function analyzeEmotions(landmarks) {
    const emotions = {
        happy: calculateHappiness(landmarks),
        sad: calculateSadness(landmarks),
        angry: calculateAnger(landmarks),
        surprised: calculateSurprise(landmarks),
        neutral: calculateNeutral(landmarks)
    };

    // Normalize to percentages
    const total = Object.values(emotions).reduce((a, b) => a + b, 0);
    Object.keys(emotions).forEach(key => {
        emotions[key] = (emotions[key] / total * 100).toFixed(1);
    });

    return emotions;
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ E_{raw} = \begin{pmatrix} E_{happy} \\ E_{sad} \\ E_{angry} \\ E_{surprised} \\ E_{neutral} \end{pmatrix} = \begin{pmatrix} \text{calculateHappiness}(L) \\ \text{calculateSadness}(L) \\ \text{calculateAnger}(L) \\ \text{calculateSurprise}(L) \\ \text{calculateNeutral}(L) \end{pmatrix} \]</p><p>\[ \Sigma = \sum_{i \in \{emotions\}} E_{raw, i} \]</p><p>\[ E_{normalized, i} = \text{round}\left(\frac{E_{raw, i}}{\Sigma} \times 100, 1\right) \quad \text{for each } i \in \{emotions\} \]</p><p><strong>Explanation:</strong></p><ul><li>\(L\): Set of facial landmarks</li><li>\(E_{raw}\): Vector of raw emotion intensity values</li><li>\(\Sigma\): Sum of all raw emotion intensities</li><li>\(E_{normalized, i}\): Normalized percentage for emotion \(i\) (rounded to 1 decimal place)</li><li>\(\text{round}(v, 1)\): Rounding the value \(v\) to 1 decimal place (equivalent to <code>toFixed(1)</code>)</li></ul><h3>4. Calculate Happiness (calculateHappiness)</h3><p>This function calculates the intensity of happiness based on facial landmarks, specifically focusing on lip and cheek movements.</p><div class=code-block><pre><code>// calculateHappiness: Computes happiness intensity
function calculateHappiness(landmarks) {
    // AU12 - Lip Corner Puller
    const lipCornerLeft = landmarks[61];
    const lipCornerRight = landmarks[291];
    const lipStretch = Math.hypot(
        lipCornerRight.x - lipCornerLeft.x,
        lipCornerRight.y - lipCornerLeft.y
    );

    // AU6 - Cheek Raiser
    const cheekLeft = landmarks[123];
    const eyeLeft = landmarks[159];
    const cheekRaiseLeft = eyeLeft.y - cheekLeft.y;

    if (!landmarks[61] || !landmarks[291] || !landmarks[123] || !landmarks[159]) {
        return 0; // Return 0 if landmarks are missing
    }

    return Math.min(1, lipStretch * 2 + cheekRaiseLeft * 3);
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ D_{lip} = \sqrt{(L_{291}.x - L_{61}.x)^2 + (L_{291}.y - L_{61}.y)^2} \]</p><p>\[ D_{cheek} = L_{159}.y - L_{123}.y \]</p><p>\[ H = \min(1, 2D_{lip} + 3D_{cheek}) \]</p><p><strong>Explanation:</strong></p><ul><li>\(L_i\): Landmark at index \(i\) in the facial landmarks array</li><li>\(D_{lip}\): Euclidean distance between left and right lip corners (Action Unit 12)</li><li>\(D_{cheek}\): Vertical distance between cheek and eye (Action Unit 6)</li><li>\(H\): Happiness intensity score, bounded to [0,1]</li><li>Coefficients 2 and 3 are weighting factors to balance the influence of each feature</li></ul><h3>5. Calculate Sadness (calculateSadness)</h3><p>This function calculates the intensity of sadness based on facial landmarks, focusing on lip depression and brow movement.</p><div class=code-block><pre><code>// calculateSadness: Computes sadness intensity
function calculateSadness(landmarks) {
    // AU15 - Lip Corner Depressor
    const lipCornerLeft = landmarks[61];
    const lipBottom = landmarks[17];
    const lipDepression = lipBottom.y - lipCornerLeft.y;

    // AU1 - Inner Brow Raiser
    const browInnerLeft = landmarks[105];
    const browInnerRight = landmarks[334];
    const browRaise = (browInnerLeft.y + browInnerRight.y) / 2;

    return Math.min(1, lipDepression * 1.5 + browRaise * 2);
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ D_{lip} = L_{17}.y - L_{61}.y \]</p><p>\[ D_{brow} = \frac{L_{105}.y + L_{334}.y}{2} \]</p><p>\[ S = \min(1, 1.5D_{lip} + 2D_{brow}) \]</p><p><strong>Explanation:</strong></p><ul><li>\(L_i\): Landmark at index \(i\) in the facial landmarks array</li><li>\(D_{lip}\): Vertical distance between lip corner and bottom lip (Action Unit 15)</li><li>\(D_{brow}\): Average height of inner brows (Action Unit 1)</li><li>\(S\): Sadness intensity score, bounded to [0,1]</li><li>Coefficients 1.5 and 2 are weighting factors to balance the influence of each feature</li></ul><h3>6. Calculate Anger (calculateAnger)</h3><p>This function calculates the intensity of anger based on facial landmarks, focusing on brow lowering and lip compression.</p><div class=code-block><pre><code>// calculateAnger: Computes anger intensity
function calculateAnger(landmarks) {
    // AU4 - Brow Lowerer
    const browOuterLeft = landmarks[46];
    const browInnerLeft = landmarks[105];
    const browLowerLeft = browInnerLeft.y - browOuterLeft.y;

    // AU23 - Lip Tightener
    const lipTop = landmarks[0];
    const lipBottom = landmarks[17];
    const lipCompression = lipBottom.y - lipTop.y;

    return Math.min(1, browLowerLeft * 2 + lipCompression * 1.2);
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ D_{brow} = L_{105}.y - L_{46}.y \]</p><p>\[ D_{lip} = L_{17}.y - L_{0}.y \]</p><p>\[ A = \min(1, 2D_{brow} + 1.2D_{lip}) \]</p><p><strong>Explanation:</strong></p><ul><li>\(L_i\): Landmark at index \(i\) in the facial landmarks array</li><li>\(D_{brow}\): Vertical distance between inner and outer brow (Action Unit 4)</li><li>\(D_{lip}\): Vertical distance between top and bottom lip (Action Unit 23)</li><li>\(A\): Anger intensity score, bounded to [0,1]</li><li>Coefficients 2 and 1.2 are weighting factors to balance the influence of each feature</li></ul><h3>7. Calculate Surprise (calculateSurprise)</h3><p>This function calculates the intensity of surprise based on facial landmarks, focusing on eye openness and jaw drop.</p><div class=code-block><pre><code>// calculateSurprise: Computes surprise intensity
function calculateSurprise(landmarks) {
    // AU5 - Upper Lid Raiser
    const eyelidLeft = landmarks[159];
    const eyeLeft = landmarks[145];
    const eyeOpenness = eyeLeft.y - eyelidLeft.y;

    // AU26 - Jaw Drop
    const chin = landmarks[152];
    const nose = landmarks[4];
    const jawDrop = chin.y - nose.y;

    return Math.min(1, eyeOpenness * 2 + jawDrop * 0.8);
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ D_{eye} = L_{145}.y - L_{159}.y \]</p><p>\[ D_{jaw} = L_{152}.y - L_{4}.y \]</p><p>\[ P = \min(1, 2D_{eye} + 0.8D_{jaw}) \]</p><p><strong>Explanation:</strong></p><ul><li>\(L_i\): Landmark at index \(i\) in the facial landmarks array</li><li>\(D_{eye}\): Vertical distance between eyelid and eye (Action Unit 5)</li><li>\(D_{jaw}\): Vertical distance between chin and nose (Action Unit 26)</li><li>\(P\): Surprise intensity score, bounded to [0,1]</li><li>Coefficients 2 and 0.8 are weighting factors to balance the influence of each feature</li></ul><h3>8. Calculate Neutral (calculateNeutral)</h3><p>This function calculates the intensity of a neutral expression by measuring deviations from a neutral facial position.</p><div class=code-block><pre><code>// calculateNeutral: Computes neutral intensity
function calculateNeutral(landmarks) {
    let deviation = 0;
    const neutralFeatures = [
        [152, 4],  // Chin to nose
        [61, 291], // Lip corners
        [105, 334] // Brows
    ];

    neutralFeatures.forEach(([i1, i2]) => {
        deviation += Math.hypot(
            landmarks[i1].x - landmarks[i2].x,
            landmarks[i1].y - landmarks[i2].y
        );
    });

    return Math.max(0, 1 - deviation * 2);
}</code></pre></div><p><strong>Mathematical Representation:</strong></p><p>\[ \delta = \sum_{(i,j) \in F} \sqrt{(L_i.x - L_j.x)^2 + (L_i.y - L_j.y)^2} \]</p><p>where \(F = \{(152, 4), (61, 291), (105, 334)\}\) represents the set of feature pairs.</p><p>\[ N = \max(0, 1 - 2\delta) \]</p><p><strong>Explanation:</strong></p><ul><li>\(L_i\): Landmark at index \(i\) in the facial landmarks array</li><li>\(F\): Set of feature pairs used to measure facial symmetry and stability</li><li>\(\delta\): Total deviation from neutral positions, calculated as the sum of Euclidean distances between landmark pairs</li><li>\(N\): Neutral expression intensity, bounded to [0,1]</li><li>The coefficient 2 is a scaling factor to ensure appropriate range for the result</li></ul></div><div class=content-section><h2 id=code-explanation>Code Explanation for Mental Health Monitoring System</h2><p>Below is a detailed explanation of the code for the mental health monitoring system using ESP32 with GSR, MAX30102, and BH1750 sensors. Each function is explained in detail with relevant mathematical formulations:</p><h3>1. Configuration and Initialization</h3><p>This section sets up the WiFi connection, GitHub settings for data storage, and sensor initialization.</p><div class=code-block><pre><code>#include "WiFi.h"
#include "HTTPClient.h"
#include "ArduinoJson.h"
#include "Wire.h"
#include "MAX30105.h"
#include "heartRate.h"
#include "BH1750.h"
#include "Base64.h"
#include "time.h"

// WiFi Configuration
const char* ssid = "Brickhouse 1";
const char* password = "AVOLUTION";

// GitHub Configuration
const char* gsrUrl = "https://api.github.com/repos/4211421036/MentalHealth/contents/GSR.json";
const char* maxUrl = "https://api.github.com/repos/4211421036/MentalHealth/contents/MAX30102.json";
const char* bhUrl = "https://api.github.com/repos/4211421036/MentalHealth/contents/BH1750.json";
const char* token = "Bearer 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";

// Time Configuration
const char* ntpServer = "pool.ntp.org";
const long gmtOffset_sec = 25200;  // GMT+7
const int daylightOffset_sec = 0;

// Sensor Objects
MAX30105 particleSensor;
BH1750 lightMeter;

// Pin Config
const int GSR_PIN = 34;
const int WINDOW_SIZE = 5;  // For moving average GSR (Boucsein, 2012)

// Sensor Variables
float eda_buffer[WINDOW_SIZE] = {0};
int buffer_index = 0;
float beatsPerMinute, beatAvg;
byte rates[4], rateSpot = 0;
long lastBeat = 0;</code></pre></div><p><strong>Explanation:</strong></p><ul><li>The libraries used include WiFi connection, HTTP client, JSON parser, I2C communication, and specific libraries for the MAX30105 and BH1750 sensors.</li><li>WiFi configuration for internet connection.</li><li>GitHub API configuration for cloud data storage.</li><li>Initialization of sensor objects and pin configuration.</li><li>WINDOW_SIZE = 5 is used for the moving average filter for GSR based on Boucsein (2012) recommendations.</li><li>Buffer variables to store and process sensor data.</li></ul><h3>2. Function getCurrentSHA</h3><p>This function retrieves the SHA value of the file on GitHub for update purposes.</p><div class=code-block><pre><code>String getCurrentSHA(const char* url) {
  HTTPClient http;
  String sha = "";
  http.begin(url);
  http.addHeader("Authorization", token);
  int httpCode = http.GET();
  
  if (httpCode == HTTP_CODE_OK) {
    DynamicJsonDocument doc(1024);
    deserializeJson(doc, http.getString());
    sha = doc["sha"].as<string>();
  }
  http.end();
  return sha;
}</string></code></pre></div><p><strong>Process Flow:</strong></p><p>\[ \text{getCurrentSHA}: \text{URL} \rightarrow \text{SHA} \]</p><p><strong>Explanation:</strong></p><ul><li>Establishes an HTTP connection to the GitHub API to obtain file metadata.</li><li>Sends a GET request with authorization token.</li><li>Extracts the SHA value from the JSON response.</li><li>SHA is a unique hash used by GitHub for version control.</li></ul><h3>3. Function uploadToGitHub</h3><p>This function uploads JSON data to GitHub with Base64 encoding.</p><div class=code-block><pre><code>void uploadToGitHub(DynamicJsonDocument doc, const char* url, String& lastSHA) {
  HTTPClient http;
  http.begin(url);
  http.addHeader("Content-Type", "application/json");
  http.addHeader("Authorization", token);

  String jsonStr;
  serializeJson(doc, jsonStr);
  String encodedData = base64::encode(jsonStr);

  String payload = "{\"message\":\"Update data\",\"content\":\"" + encodedData + "\",\"sha\":\"" + last SHA + "\"}";

  int httpCode = http.PUT(payload);
  if (httpCode == HTTP_CODE_OK) {
    DynamicJsonDocument respDoc(1024);
    deserializeJson(respDoc, http.getString());
    lastSHA = respDoc["content"]["sha"].as<string>();
  }
  http.end();
}</string></code></pre></div><p><strong>Process Flow:</strong></p><p>\[ \text{JSON} \xrightarrow{\text{serialize}} \text{String} \xrightarrow{\text{Base64}} \text{EncodedString} \xrightarrow{\text{HTTP PUT}} \text{GitHub} \]</p><p><strong>Explanation:</strong></p><ul><li>Takes a JSON document, URL endpoint, and a reference to lastSHA.</li><li>Converts the JSON document to a string.</li><li>Encodes the string with Base64 (required by GitHub API).</li><li>Creates a payload for the PUT request containing the encoded data and previous SHA.</li><li>Updates lastSHA with the new SHA value from the GitHub response.</li></ul><h3>4. Function getTimestamp</h3><p>This function retrieves the current timestamp from the NTP server.</p><div class=code-block><pre>
                            <code>
String getTimestamp() {
    struct tm timeinfo;
    if(!getLocalTime(&timeinfo)) return "";
    char buffer[20];
    strftime(buffer, sizeof(buffer), "%Y-%m-%d %H:%M:%S", &timeinfo);
    return String(buffer);
}
                            </code>
                        </pre></div><p><strong>Output Format:</strong></p><p>\[ \text{Timestamp} = \text{YYYY-MM-DD HH:MM:SS} \]</p><p><strong>Explanation:</strong></p><ul><li>Uses NTP (Network Time Protocol) to obtain accurate time.</li><li>Converts time to a readable string format: year-month-day hour:minute:second.</li><li>Important for providing consistent timestamps on sensor data.</li></ul><h3>5. Function edaMovingAverage</h3><p>This function implements a moving average filter for EDA (Electrodermal Activity) signal based on Boucsein (2012) methodology.</p><div class=code-block><pre>
                            <code>
// Moving average function for EDA tonic (Boucsein, 2012)
float edaMovingAverage(float newVal) {
    eda_buffer[buffer_index] = newVal;
    buffer_index = (buffer_index + 1) % WINDOW_SIZE;
    float sum = 0;
    return sum/WINDOW_SIZE;
}
                            </code>
                        </pre></div><p><strong>Mathematical Formulation:</strong></p><p>\[ B[j] = x_{\text{new}} \]</p><p>\[ j = (j + 1) \mod W \]</p><p>\[ \bar{x} = \frac{1}{W} \sum_{i=0}^{W-1} B[i] \]</p><p><strong>Explanation:</strong></p><ul><li>\(B\): Circular buffer to store the latest EDA values.</li><li>\(j\): Current buffer index.</li><li>\(W\): Window size (WINDOW_SIZE = 5).</li><li>\(x_{\text{new}}\): New EDA value.</li><li>\(\bar{x}\): Average EDA value (EDA tonic).</li><li>This method, based on Boucsein (2012), helps separate the tonic (baseline) component from the EDA signal.</li></ul><h3>6. Function setup</h3><p>This function initializes the connection and sensors when the system is powered on.</p><div class=code-block><pre><code>void setup() {
  Serial.begin(115200);

  WiFi.begin(ssid, password);
  int wifiTimeout = 0;
  while (WiFi.status() != WL_CONNECTED && wifiTimeout) {
    delay(500);
    Serial.print(".");
    wifiTimeout++;
  }
  
  if (WiFi.status() == WL_CONNECTED) {
    Serial.println("\nConnected to WiFi");
    configTime(gmtOffset_sec, daylightOffset_sec, ntpServer);
  } else {
    Serial.println("\nFailed to connect WiFi");
    ESP.restart();
  }
  
  // Initialize Sensors
  Wire.begin();
  if (!particleSensor.begin(Wire, I2C_SPEED_FAST)) {
    Serial.println("MAX30102 not found");
  }
  particleSensor.setup();
  lightMeter.begin();

  configTime(gmtOffset_sec, daylightOffset_sec, ntpServer);
}</code></pre></div><p><strong>Process Flow:</strong></p><p>\[ \text{Initialize Serial} \rightarrow \text{WiFi Connection} \rightarrow \text{NTP Configuration} \rightarrow \text{Sensor Initialization} \]</p><p><strong>Explanation:</strong></p><ul><li>Initializes serial communication with a baud rate of 115200.</li><li>Attempts to connect to WiFi with a timeout of 10 seconds (20 x 500ms).</li><li>If the connection fails, the system will restart.</li><li>Initializes the I2C bus (Wire) for communication with the sensors.</li><li>Configures the MAX30102 and BH1750 sensors.</li><li>Sets up NTP for time synchronization.</li></ul><h3>7. Function loop</h3><p>The main function that runs repeatedly to read sensors, process data, and upload it to GitHub.</p><div class=code-block><pre>
                            <code>
void loop() {
  if (WiFi.status() != WL_CONNECTED) {
    Serial.println("WiFi disconnected. Reconnecting...");
    WiFi.reconnect();
    delay(5000);
    return;
  }
  static unsigned long lastUpload = 0;
  
  // Read all sensors
  float gsrRaw = analogRead(GSR_PIN);
  float edaTonic = edaMovingAverage(gsrRaw);
  float edaPhasic = gsrRaw - edaTonic;  // Boucsein (2012)
  
  long irValue = particleSensor.getIR();
  if(irValue > 50000 && checkForBeat(irValue)) {  // Shaffer et al. (2014)
    long delta = millis() - lastBeat;
    lastBeat = millis();
    beatsPerMinute = 60 / (delta / 1000.0);
    if(beatsPerMinute) {
      rates[rateSpot++] = (byte)beatsPerMinute;
      rateSpot %= 4;
      beatAvg = 0;
      for(byte x=0; x; x++) beatAvg += rates[x];
      beatAvg /= 4;
    }
  }

  float lux = lightMeter.readLightLevel();  // Golden et al. (2005)

  if(millis() - lastUpload >= 10000) {  // Upload every 10 seconds
    String timestamp = getTimestamp();
    
    // Create JSON document for each sensor
    DynamicJsonDocument gsrDoc(256);
    gsrDoc["sensor"] = "GSR";
    gsrDoc["tonic"] = edaTonic;
    gsrDoc["phasic"] = edaPhasic;
    gsrDoc["timestamp"] = timestamp;
    
    DynamicJsonDocument maxDoc(256);
    maxDoc["sensor"] = "MAX30102";
    maxDoc["bpm"] = beatsPerMinute;
    maxDoc["hrv"] = beatAvg;  // SDNN calculated offline
    maxDoc["timestamp"] = timestamp;
    
    DynamicJsonDocument bhDoc(256);
    bhDoc["sensor"] = "BH1750";
    bhDoc["lux"] = lux;
    bhDoc["timestamp"] = timestamp;

    // Upload to GitHub
    if(lastSHA_GSR == "") lastSHA_GSR = getCurrentSHA(gsrUrl);
    uploadToGitHub(gsrDoc, gsrUrl, lastSHA_GSR);
    
    if(lastSHA_MAX == "") lastSHA_MAX = getCurrentSHA(maxUrl);
    uploadToGitHub(maxDoc, maxUrl, lastSHA_MAX);
    
    if(lastSHA_BH == "") lastSHA_BH = getCurrentSHA(bhUrl);
    uploadToGitHub(bhDoc, bhUrl, lastSHA_BH);

    lastUpload = millis();
  }
}</code></pre></div><p><strong>Mathematical Formulation:</strong></p><h4>Processing GSR (Galvanic Skin Response)\[ \text{EDA}_{\text{tonic}} = \text{edaMovingAverage}(\text{gsrRaw}) \]<p></p><p>\[ \text{EDA}_{\text{phasic}} = \text{gsrRaw} - \text{EDA}_{\text{tonic}} \]</p><h4>Processing Heart Rate</h4><p>\[ \Delta t = t_{\text{current}} - t_{\text{lastBeat}} \]</p><p>\[ \text{BPM} = \frac{60}{\Delta t / 1000} \]</p><p>\[ \text{beatAvg} = \frac{1}{4} \sum_{i=0}^{3} \text{rates}[i] \]</p><p><strong>Comprehensive Explanation:</strong></p><ul><li><strong>Connection Monitoring:</strong> Checks WiFi status and reconnects if disconnected.</li><li><strong>Reading GSR (Galvanic Skin Response):</strong><ul><li>Reads raw value from the analog pin (GSR_PIN).</li><li>Calculates the tonic (baseline) component using moving average.</li><li>Calculates the phasic component as the difference between raw and tonic (Boucsein, 2012).</li></ul></li><li><strong>Reading Heart Rate (MAX30102):</strong><ul><li>Reads IR value from the MAX30102 sensor.</li><li>Detects beats with a threshold of 50000 (Shaffer et al., 2014).</li><li>Calculates BPM from the interval between beats.</li><li>Applies averaging filter for the last 4 readings.</li><li>Validates BPM within the physiological range of 20-255.</li></ul></li><li><strong>Reading Light Level (BH1750):</strong><ul><li>Reads lux value from the BH1750 sensor (Golden et al., 2005).</li></ul></li><li><strong>Upload Period:</strong><ul><li>Uses a timer to upload data every 10 seconds.</li><li>Creates JSON documents for each sensor with timestamps.</li><li>Uploads data to the GitHub repository with SHA update mechanism.</li></ul></li></ul><h3>8. GSR Component Analysis</h3><p>The Galvanic Skin Response (GSR) or Electrodermal Activity (EDA) is processed according to Boucsein (2012) methodology.</p><p><strong>Complete Mathematical Formulation:</strong></p><p>\[ \text{EDA}_{\text{raw}}(t) = \text{analogRead}(\text{GSR\_PIN}) \]</p><p>\[ \text{EDA}_{\text{tonic}}(t) = \frac{1}{W} \sum_{i=0}^{W-1} \text{EDA}_{\text{buffer}}[i] \]</p><p>\[ \text{EDA}_{\text{phasic}}(t) = \text{EDA}_{\text{raw}}(t) - \text{EDA}_{\text{tonic}}(t) \]</p><p><strong>Explanation:</strong></p><ul><li><strong>EDA<sub>raw</sub></strong>: Raw EDA signal from the sensor, measuring skin conductivity.</li><li><strong>EDA<sub>tonic</sub></strong>: Tonic component of EDA, representing long-term skin conductivity levels.</li><li><strong>EDA<sub>phasic</sub></strong>: Phasic component of EDA, representing short-term skin conductivity responses.</li><li><strong>W</strong>: Window size for moving average (5 samples).</li><li>This decomposition method aligns with Boucsein (2012) for stress and emotional response analysis.</li></ul><h3>9. Heart Rate Analysis</h3><p>Heart rate is measured using the MAX30102 sensor following the methodology from Shaffer et al. (2014).</p><p><strong>Complete Mathematical Formulation:</strong></p><p>\[ \text{IR}(t) = \text{particleSensor.getIR()} \]</p><p>\[ \text{Beat detection} = \begin{cases} 1, & \ if \text{IR}(t) > 50000 \text{ and } \text{checkForBeat}(\text{IR}(t)) \\ 0, & \text{otherwise} \end{cases} \]</p><p>\[ \Delta t = t_{\text{current}} - t_{\text{lastBeat}} \]</p><p>\[ \text{BPM} = \frac{60 \times 1000}{\Delta t} \]</p><p>\[ \text{BPM}_{\text{valid}} = \begin{cases} \end{cases} \]</p><p>\[ \text{HRV}_{\text{avg}} = \frac{1}{4} \sum_{i=0}^{3} \text{rates}[i] \]</p><p><strong>Explanation:</strong></p><ul><li><strong>IR(t)</strong>: Infrared value read from the MAX30102 sensor.</li><li><strong>Beat detection</strong>: Function to detect heartbeats.</li><li><strong>Δt</strong>: Time interval between heartbeats (ms).</li><li><strong>BPM</strong>: Beats Per Minute, calculated from the interval between beats.</li><li><strong>BPM<sub>valid</sub></strong>: Validated BPM within physiological range (20-255).</li><li><strong>HRV<sub>avg</sub></strong>: Heart Rate Variability, calculated as the average of the last 4 measurements.</li><li>Threshold of 50000 for beat detection refers to Shaffer et al. (2014).</li></ul><h3>10. Light Level Analysis</h3><p>Light levels are measured using the BH1750 sensor, referencing Golden et al. (2005) regarding the impact of light on mental health.</p><p><strong>Formulation:</strong></p><p>\[ \text{Lux}(t) = \text{lightMeter.readLightLevel()} \]</p><p><strong>Explanation:</strong></p><ul><li><strong>Lux(t)</strong>: Light level measured in lux.</li><li>Measurement of light levels is crucial in mental health analysis based on research by Golden et al. (2005).</li><li>Light levels correlate with circadian rhythms and melatonin production.</li></ul><h3>11. Data Upload Mechanism</h3><p>Sensor data is uploaded to GitHub as a cloud storage system with SHA mechanism for version control.</p><p><strong>Process Flow:</strong></p><p>\[ \text{Sensor Data} \rightarrow \text{JSON Documents} \rightarrow \text{Base64 Encoding} \rightarrow \text{HTTP PUT} \rightarrow \text{GitHub} \]</p><p><strong>Explanation:</strong></p><ul><li><strong>Upload Interval</strong>: Data is uploaded every 10 seconds (10000 ms).</li><li><strong>Data Format</strong>: JSON structure with sensor values and timestamps.</li><li><strong>SHA Mechanism</strong>: SHA values are used to ensure data integrity and conflict handling.</li><li><strong>Base64 Encoding</strong>: JSON data is encoded with Base64 as per GitHub API requirements.</li><li>This system allows for longitudinal data recording for long-term mental health trend analysis.</li></ul><h3>12. Scientific References</h3><p>This code implementation refers to several scientific references:</p><ul><li><strong>Boucsein, W. (2012)</strong>: "Electrodermal Activity" - Standard reference for processing GSR/EDA signals, including tonic and phasic component separation methods.</li><li><strong>Shaffer et al. (2014)</strong>: "A healthy heart is not a metronome: an integrative review of the heart's anatomy and heart rate variability" - Guidelines for processing and interpreting heart rate variability data.</li><li><strong>Golden et al. (2005)</strong>: "The efficacy of light therapy in the treatment of mood disorders: a review and meta-analysis of the evidence" - Research on the impact of light levels on mood and mental health.</li></ul></h4></div></div><div class=sidebar><div class=sidebar-section><h3 class=sidebar-title>ON THIS PAGE</h3><ul class=sidebar-nav id=sidebar-nav></ul></div></div></div><footer class=footer><p>&copy; 2025 Mental Health Website. All rights reserved.</p></footer><script nonce="WFV9sDq7d03R5LMneBB3ow==">document.addEventListener("DOMContentLoaded",function(){let t=document.querySelectorAll("h1, h2, h3"),e=document.getElementById("sidebar-nav");function a(){var e=document.querySelectorAll(".sidebar-nav a");let a="";t.forEach(e=>{var t=e.getBoundingClientRect();t.top<=150&&150<=t.bottom&&(a="#"+e.id)}),e.forEach(e=>{e.classList.remove("active"),e.getAttribute("href")===a&&e.classList.add("active")})}e.addEventListener("click",e=>{"A"===e.target.tagName&&(e.preventDefault(),e=document.querySelector(e.target.getAttribute("href")))&&window.scrollTo({top:e.offsetTop-100,behavior:"smooth"})});{let o="";t.forEach(e=>{var t=parseInt(e.tagName.replace("H","")),a=e.id||e.textContent.toLowerCase().replace(/[^\w\s]/g,"").replace(/\s+/g,"-"),t=(e.id=a,"level-"+t);o+=`
                <li class="${t}">
                    <a href="#${a}">${e.textContent}</a>
                </li>
            `}),e.innerHTML=o}a(),window.addEventListener("scroll",a)})</script></div><script nonce="WFV9sDq7d03R5LMneBB3ow==">function loadThirdParty(e){var r,a=e.dataset.src,t=e.dataset.type;"script"===t?((r=document.createElement("script")).src=a,r.async=!0,e.parentNode.replaceChild(r,e)):"iframe"===t&&((r=document.createElement("iframe")).src=a,Object.assign(r,{width:e.dataset.width||"100%",height:e.dataset.height||"100%",frameborder:"0"}),e.parentNode.replaceChild(r,e)),performance.mark("third-party-load-"+a),performance.measure("third-party-loading","app-init-start","third-party-load-"+a)}performance.mark("app-init-start");let observer=new IntersectionObserver(e=>{e.forEach(e=>{e.isIntersecting&&(loadThirdParty(e.target),observer.unobserve(e.target))})},{rootMargin:"50px"});function sendPerformanceMetrics(){var e=performance.getEntriesByType("measure");console.log("Performance metrics:",e)}window.addEventListener("pageshow",function(e){performance.mark("pageshow-start"),e.persisted&&(console.log("Page restored from bfcache"),performance.measure("bfcache-restoration","pageshow-start"))}),window.addEventListener("load",function(){performance.mark("page-load-complete"),performance.measure("total-page-load","app-init-start","page-load-complete"),document.querySelectorAll("[data-lazy]").forEach(e=>{observer.observe(e)})}),window.addEventListener("pagehide",function(e){console.log("Page is being unloaded")}),document.addEventListener("visibilitychange",function(){"hidden"===document.visibilityState&&(performance.mark("page-hide"),performance.measure("page-visible-duration","app-init-start","page-hide"),sendPerformanceMetrics(),console.log("Page hidden, prepare for restoration"))})</script></body></html>